#!/usr/bin/env python3
"""
–≠—Ç–∞–ø 2: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
"""
import json
import os
from text_cleaner import TextCleaner

def main():
    print("=" * 60)
    print("–≠–¢–ê–ü 2: –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ò –û–ß–ò–°–¢–ö–ê –¢–ï–ö–°–¢–ê")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    input_file = "kommersant_articles.jsonl"
    if not os.path.exists(input_file):
        print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return
    
    print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ {input_file}...")
    articles = []
    with open(input_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                articles.append(json.loads(line))
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ—á–∏—Å—Ç–∏—Ç–µ–ª—è —Ç–µ–∫—Å—Ç–∞
    cleaner = TextCleaner(remove_stopwords=True, language='russian')
    
    print("üßπ –ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤...")
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ç–µ–π
    cleaned_articles = cleaner.batch_clean(
        articles,
        clean_title=True,
        clean_text=True,
        remove_html=True,
        remove_urls=True,
        remove_phones=True,
        remove_dates=True,
        remove_numbers=False,  # –û—Å—Ç–∞–≤–ª—è–µ–º —á–∏—Å–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        normalize_whitespace=True,
        normalize_punctuation=True,
        to_lowercase=False,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–≥–∏—Å—Ç—Ä
        remove_stopwords=True
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    output_file = "kommersant_articles_cleaned.jsonl"
    with open(output_file, 'w', encoding='utf-8') as f:
        for article in cleaned_articles:
            f.write(json.dumps(article, ensure_ascii=False) + '\n')
    
    print(f"‚úÖ –û—á–∏—â–µ–Ω–æ {len(cleaned_articles)} —Å—Ç–∞—Ç–µ–π")
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_words_before = sum(len(article['text'].split()) for article in articles)
    total_words_after = sum(len(article['text'].split()) for article in cleaned_articles)
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –°–ª–æ–≤ –¥–æ –æ—á–∏—Å—Ç–∫–∏: {total_words_before:,}")
    print(f"   –°–ª–æ–≤ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {total_words_after:,}")
    print(f"   –°–æ–∫—Ä–∞—â–µ–Ω–∏–µ: {((total_words_before - total_words_after) / total_words_before * 100):.1f}%")
    
    print("\nüéâ –≠—Ç–∞–ø 2 –∑–∞–≤–µ—Ä—à–µ–Ω!")

if __name__ == "__main__":
    main()
